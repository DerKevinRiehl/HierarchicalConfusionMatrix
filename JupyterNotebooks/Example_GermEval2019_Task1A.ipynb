{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adequate-spanking",
   "metadata": {},
   "source": [
    "# Example GermEval2019_Task1A (1-Level-Tree, MPL, MLNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "together-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GermEval2019 Competition on hierarchical classification of texts\n",
    "# Task 1A: (1-Level-Tree, MPL, MLNP) classification problem\n",
    "# More infos can be found here: https://2019.konvens.org/germeval\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from HierarchicalConfusion import determineHierarchicalConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods\n",
    "\"\"\"\n",
    "This method loads the structure / classification hierarchy for GermEval2019 data from a given file,\n",
    "and returns it as a graph object.\n",
    "\"\"\"\n",
    "def loadHierarchy(file, level=-1):\n",
    "    # Load GermEval2019 Hierarchy\n",
    "    f = open(file, \"r\", encoding=\"utf8\")\n",
    "    edges = []\n",
    "    for l in f.readlines():\n",
    "        edges.append(l.replace(\"\\n\",\"\").split(\"\\t\"))\n",
    "    f.close()\n",
    "    # Determine root nodes\n",
    "    root_nodes = []\n",
    "    for i in range(0,len(edges)):\n",
    "        cat = edges[i][0]\n",
    "        if(cat in root_nodes):\n",
    "            continue\n",
    "        found = False\n",
    "        for j in range(0,len(edges)):\n",
    "            if(cat == edges[j][1] and i != j):\n",
    "                found = True\n",
    "                break\n",
    "        if(not found):\n",
    "            root_nodes.append(cat)\n",
    "    # Add root node connection\n",
    "    if(level==1):\n",
    "        edges = []\n",
    "    for n in root_nodes:\n",
    "        edges.append([\"root\",n])\n",
    "    # Convert to Networkx Graph\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_edges_from(edges)\n",
    "    return graph\n",
    "\n",
    "\"\"\"\n",
    "This method loads the evaluation data from GermEval2019_Task1A (true labels and prediction labels)\n",
    "\"\"\"\n",
    "def loadEvaluationData_GermEval2019_Task1A(true_label_file, pred_label_file):    # Load True Labels of task A (Tree(1Level), MPL, MLNP)\n",
    "    true_label_data = {}\n",
    "    pred_label_data = {}\n",
    "    eval_label_data = {}\n",
    "    # Load true_label_data\n",
    "    f = open(true_label_file, \"r\", encoding=\"utf8\")\n",
    "    f.readline()\n",
    "    line = f.readline()\n",
    "    while not line.startswith(\"subtask_b\"):\n",
    "        parts = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "        true_label_data[parts[0]] = parts[1:]\n",
    "        line = f.readline()\n",
    "    f.close()\n",
    "    # load pred_label_data\n",
    "    f = open(pred_label_file, \"r\", encoding=\"utf8\")\n",
    "    f.readline()\n",
    "    line = f.readline()\n",
    "    while not line.startswith(\"subtask_b\") and not line==\"\":\n",
    "        parts = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "        predPaths = []\n",
    "        for n in parts[1:]:\n",
    "            predPaths.append([\"root\",n])\n",
    "        pred_label_data[parts[0]] = predPaths\n",
    "        line = f.readline()\n",
    "    f.close()\n",
    "    # Process evaluation data results\n",
    "    for key in true_label_data:\n",
    "        if(key in pred_label_data):\n",
    "            eval_label_data[key] = {}\n",
    "            eval_label_data[key][\"true\"] = true_label_data[key]\n",
    "            eval_label_data[key][\"pred\"] = pred_label_data[key]\n",
    "    n_nopredictions = 0\n",
    "    for key in true_label_data:\n",
    "        if(key not in pred_label_data):\n",
    "            eval_label_data[key] = {}\n",
    "            eval_label_data[key][\"true\"] = true_label_data[key]\n",
    "            eval_label_data[key][\"pred\"] = [[\"root\"]]\n",
    "            n_nopredictions += 1\n",
    "    return eval_label_data, n_nopredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dated-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algo\tF1\tPPV\tREC\tACC\tMCC\tTP\tTN\tFP\tFN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramFiles\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averbis__BOHB_CNN.txt \t 0.8337371639552325 \t 0.8608529902311175 \t 0.8082774049217002 \t 0.9575139310670165 \t 3218.0743277230877 \t 3613 \t 28863 \t 584 \t 857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramFiles\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comtravo-DS__global_clf_cnn.txt \t 0.5332521686196926 \t 0.4040590405904059 \t 0.7838926174496644 \t 0.8469064317268575 \t nan \t 3504 \t 30429 \t 5168 \t 966\n",
      "Comtravo-DS__local_clf_logit_cnn.txt \t 0.7988742151980949 \t 0.7739093959731543 \t 0.825503355704698 \t 0.9470126907172394 \t nan \t 3690 \t 29517 \t 1078 \t 780\n",
      "DFKI-SLT__full.txt \t 0.8613669964744683 \t 0.8760120286837844 \t 0.8472035794183446 \t 0.9640826188161112 \t nan \t 3787 \t 28933 \t 536 \t 683\n",
      "DFKI-SLT__full2.txt \t 0.8411063534313158 \t 0.8712538959482139 \t 0.8129753914988814 \t 0.9591672862453532 \t 3008.3564277924306 \t 3634 \t 28618 \t 537 \t 836\n",
      "DFKI-SLT__text-only.txt \t 0.8559726962457338 \t 0.8708333333333333 \t 0.8416107382550335 \t 0.9627603247440876 \t nan \t 3762 \t 28968 \t 558 \t 708\n",
      "EricssonResearch__fconv_4LYFP_7EKHC_WNG1A.txt \t 0.6590935435261389 \t 0.6839066634592254 \t 0.6360178970917226 \t 0.9123894068932646 \t 1742.0148188810792 \t 2843 \t 27785 \t 1314 \t 1627\n",
      "EricssonResearch__fconv_A6C1Y.txt \t 0.867034736599954 \t 0.892282196969697 \t 0.8431767337807606 \t 0.965814998817128 \t nan \t 3769 \t 28891 \t 455 \t 701\n",
      "EricssonResearch__fconv_F8V17.txt \t 0.8503283788454891 \t 0.8766928011404134 \t 0.825503355704698 \t 0.9614939973321476 \t nan \t 3690 \t 28746 \t 519 \t 780\n",
      "fosil-hsmw__SVM_ECC.txt \t 0.8373297309467522 \t 0.8427373668706095 \t 0.8319910514541387 \t 0.9577077296806861 \t nan \t 3719 \t 29003 \t 694 \t 751\n",
      "HSHL__LogisticRegression_NaiveBayes1.txt \t 0.8201034405217 \t 0.8243670886075949 \t 0.8158836689038031 \t 0.9531121791114758 \t nan \t 3647 \t 28877 \t 777 \t 823\n",
      "HSHL__LogisticRegression_NaiveBayes2.txt \t 0.8163081428088749 \t 0.8219550918575641 \t 0.810738255033557 \t 0.9521237561276309 \t 2744.547164758826 \t 3624 \t 28812 \t 785 \t 846\n",
      "HUIU__multi.txt \t 0.8067076579094467 \t 0.8062569832402234 \t 0.807158836689038 \t 0.9493630106897056 \t nan \t 3608 \t 28808 \t 867 \t 862\n",
      "knowcup__DL_single_test.txt \t 0.8442687747035573 \t 0.8524515393386545 \t 0.836241610738255 \t 0.9596276019556753 \t 2520.8416851467196 \t 3738 \t 29040 \t 647 \t 732\n",
      "LT-UHH__baseline.txt \t 0.8001914333572625 \t 0.8600823045267489 \t 0.7480984340044743 \t 0.9510235204410816 \t nan \t 3344 \t 29084 \t 544 \t 1126\n",
      "LT-UHH__baseline_wo_correction.txt \t 0.8001914333572625 \t 0.8600823045267489 \t 0.7480984340044743 \t 0.9510235204410816 \t nan \t 3344 \t 29084 \t 544 \t 1126\n",
      "LT-UHH__contender.txt \t 0.7200378071833649 \t 0.6234042553191489 \t 0.8521252796420582 \t 0.9190843031197071 \t 2714.591004432685 \t 3809 \t 29835 \t 2301 \t 661\n",
      "NoTeam__GRU_Attention_ensemble1.txt \t 0.29118907027903207 \t 0.1964229928147454 \t 0.5626398210290827 \t 0.7251935809673438 \t nan \t 2515 \t 29796 \t 10289 \t 1955\n",
      "Raghavan__SVM-BPEB.txt \t 0.8575351870923447 \t 0.8777231201686577 \t 0.838255033557047 \t 0.963355408388521 \t 2630.5903122442137 \t 3747 \t 28983 \t 522 \t 723\n",
      "twistbytes__sklearn_hier_threshold.txt \t 0.7722051631979984 \t 0.7853342586167014 \t 0.7595078299776287 \t 0.9421599768986428 \t 6635.155200537555 \t 3395 \t 29232 \t 928 \t 1075\n",
      "twistbytes__sklearn_hier_threshold_and_roots_baseline_thresholding.txt \t 0.8490191756667401 \t 0.8366637706342311 \t 0.8617449664429531 \t 0.9606016161964743 \t nan \t 3852 \t 29551 \t 752 \t 618\n",
      "twistbytes__thresholding.txt \t 0.0 \t 0.0 \t 0.0 \t 0.7713248157769178 \t -482.6999169690939 \t 0 \t 29099 \t 4157 \t 4470\n"
     ]
    }
   ],
   "source": [
    "# Load GermEval2019 hierarchy\n",
    "path = \"CaseStudies/GermEval2019\"\n",
    "hierarchy_file = os.path.join(path,\"hierarchy.txt\")\n",
    "graph = loadHierarchy(hierarchy_file, level=1)\n",
    "\n",
    "# List all available algorithms\n",
    "true_label_file = os.path.join(path,\"blurbs_test_label.txt\")\n",
    "algo_folder = os.listdir(os.path.join(path, \"system-submissions/test-phase-txt\"))\n",
    "\n",
    "# For each algorithm determine hierarchical confusion matrix\n",
    "print(\"algo\\tF1\\tPPV\\tREC\\tACC\\tMCC\\tTP\\tTN\\tFP\\tFN\")\n",
    "for algo in algo_folder:\n",
    "    pred_label_file = os.path.join(path, \"system-submissions/test-phase-txt\", algo)\n",
    "    eval_label_data, nn = loadEvaluationData_GermEval2019_Task1A(true_label_file, pred_label_file)\n",
    "    # Determine Confusion Matrix\n",
    "    h_confusion = {}\n",
    "    h_confusion_total = []\n",
    "    for key in eval_label_data:\n",
    "        h_confusion[key] = determineHierarchicalConfusionMatrix(graph, eval_label_data[key][\"true\"], eval_label_data[key][\"pred\"])\n",
    "        h_confusion_total.append(h_confusion[key])\n",
    "    h_confusion_total = np.sum(np.asarray(h_confusion_total),axis=0)\n",
    "    F1 = 2*h_confusion_total[0]/(2*h_confusion_total[0]+h_confusion_total[2]+h_confusion_total[3])\n",
    "    PPV = h_confusion_total[0]/(h_confusion_total[0]+h_confusion_total[2])\n",
    "    REC = (h_confusion_total[0])/(h_confusion_total[0]+h_confusion_total[3])\n",
    "    ACC = (h_confusion_total[0]+h_confusion_total[1])/(h_confusion_total[0]+h_confusion_total[1]+h_confusion_total[2]+h_confusion_total[3])\n",
    "    MCC = (h_confusion_total[0]*h_confusion_total[1]-h_confusion_total[2]*h_confusion_total[3])/np.sqrt((h_confusion_total[0]+h_confusion_total[2])*(h_confusion_total[0]+h_confusion_total[3])*(h_confusion_total[1]+h_confusion_total[2])*(h_confusion_total[1]+h_confusion_total[3]))\n",
    "    print(algo, \"\\t\", F1, \"\\t\", PPV, \"\\t\", REC, \"\\t\", ACC, \"\\t\", MCC, \"\\t\", h_confusion_total[0], \"\\t\", h_confusion_total[1], \"\\t\", h_confusion_total[2], \"\\t\", h_confusion_total[3])    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
